{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enable module reloading\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import time;\n",
    "\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding, Input, Dense, Flatten, concatenate\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from src.data.load_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset(filename='../data/Jester-Dataset-ratings.csv')\n",
    "user_ids, joke_ids, ratings = get_data(df, batch_size=20000)\n",
    "# batch_size = 20000\n",
    "        \n",
    "# matrix = df[0:batch_size].pivot(index='USER_ID', columns='JOKE_ID', values='Rating').fillna(0)\n",
    "# user_ids = matrix.index.tolist()\n",
    "# joke_ids = matrix.columns.tolist()\n",
    "# ratings = matrix.values.flatten().tolist()\n",
    "# ratings = np.array(cur_df.pivot(index='USER_ID', columns='JOKE_ID', values='Rating').fillna(0)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_onehot = to_categorical(user_ids)\n",
    "joke_onehot = to_categorical(joke_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = len(user_onehot[0])\n",
    "n_jokes = len(joke_onehot[0])\n",
    "# n_users = len(np.unique(user_ids))\n",
    "# n_jokes = len(np.unique(joke_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = n_users if n_users > n_jokes else n_jokes\n",
    "user_onehot = to_categorical(user_ids, num_classes=num_classes)\n",
    "joke_onehot = to_categorical(joke_ids, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "511"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_concat = np.concatenate([user_onehot, joke_onehot], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(vector_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,   5],\n",
       "       [  1,   7],\n",
       "       [  1,   8],\n",
       "       ...,\n",
       "       [510,  68],\n",
       "       [510,  24],\n",
       "       [510,  25]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(zip(user_ids, joke_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "16000/16000 [==============================] - 2s 135us/sample - loss: 33.1643 - accuracy: 0.0018 - val_loss: 33.1490 - val_accuracy: 7.5000e-04\n",
      "Epoch 2/20\n",
      "16000/16000 [==============================] - 1s 88us/sample - loss: 32.9872 - accuracy: 0.0018 - val_loss: 33.0960 - val_accuracy: 7.5000e-04\n",
      "Epoch 3/20\n",
      "16000/16000 [==============================] - 1s 92us/sample - loss: 32.9513 - accuracy: 0.0018 - val_loss: 33.0796 - val_accuracy: 7.5000e-04\n",
      "Epoch 4/20\n",
      "16000/16000 [==============================] - 1s 91us/sample - loss: 32.9375 - accuracy: 0.0018 - val_loss: 33.0724 - val_accuracy: 7.5000e-04\n",
      "Epoch 5/20\n",
      "16000/16000 [==============================] - 1s 87us/sample - loss: 32.9305 - accuracy: 0.0018 - val_loss: 33.0686 - val_accuracy: 7.5000e-04\n",
      "Epoch 6/20\n",
      "16000/16000 [==============================] - 1s 86us/sample - loss: 32.9265 - accuracy: 0.0018 - val_loss: 33.0664 - val_accuracy: 7.5000e-04\n",
      "Epoch 7/20\n",
      "16000/16000 [==============================] - 1s 88us/sample - loss: 32.9239 - accuracy: 0.0018 - val_loss: 33.0649 - val_accuracy: 7.5000e-04\n",
      "Epoch 8/20\n",
      "16000/16000 [==============================] - 1s 89us/sample - loss: 32.9221 - accuracy: 0.0018 - val_loss: 33.0639 - val_accuracy: 7.5000e-04\n",
      "Epoch 9/20\n",
      "16000/16000 [==============================] - 1s 87us/sample - loss: 32.9208 - accuracy: 0.0018 - val_loss: 33.0632 - val_accuracy: 7.5000e-04\n",
      "Epoch 10/20\n",
      "16000/16000 [==============================] - 1s 87us/sample - loss: 32.9199 - accuracy: 0.0018 - val_loss: 33.0627 - val_accuracy: 7.5000e-04\n",
      "Epoch 11/20\n",
      "16000/16000 [==============================] - 1s 89us/sample - loss: 32.9192 - accuracy: 0.0018 - val_loss: 33.0623 - val_accuracy: 7.5000e-04\n",
      "Epoch 12/20\n",
      "16000/16000 [==============================] - 1s 85us/sample - loss: 32.9186 - accuracy: 0.0018 - val_loss: 33.0620 - val_accuracy: 7.5000e-04\n",
      "Epoch 13/20\n",
      "16000/16000 [==============================] - 1s 86us/sample - loss: 32.9181 - accuracy: 0.0018 - val_loss: 33.0617 - val_accuracy: 7.5000e-04\n",
      "Epoch 14/20\n",
      "16000/16000 [==============================] - 1s 86us/sample - loss: 32.9177 - accuracy: 0.0018 - val_loss: 33.0615 - val_accuracy: 7.5000e-04\n",
      "Epoch 15/20\n",
      "16000/16000 [==============================] - 1s 92us/sample - loss: 32.9174 - accuracy: 0.0018 - val_loss: 33.0614 - val_accuracy: 7.5000e-04\n",
      "Epoch 16/20\n",
      "16000/16000 [==============================] - 1s 92us/sample - loss: 32.9172 - accuracy: 0.0018 - val_loss: 33.0612 - val_accuracy: 7.5000e-04\n",
      "Epoch 17/20\n",
      "16000/16000 [==============================] - 1s 87us/sample - loss: 32.9170 - accuracy: 0.0018 - val_loss: 33.0611 - val_accuracy: 7.5000e-04\n",
      "Epoch 18/20\n",
      "16000/16000 [==============================] - 1s 88us/sample - loss: 32.9168 - accuracy: 0.0018 - val_loss: 33.0610 - val_accuracy: 7.5000e-04\n",
      "Epoch 19/20\n",
      "16000/16000 [==============================] - 1s 86us/sample - loss: 32.9166 - accuracy: 0.0018 - val_loss: 33.0609 - val_accuracy: 7.5000e-04\n",
      "Epoch 20/20\n",
      "16000/16000 [==============================] - 1s 88us/sample - loss: 32.9165 - accuracy: 0.0018 - val_loss: 33.0609 - val_accuracy: 7.5000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdb8e071710>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models.model_GMF import JokeRecommender\n",
    "\n",
    "model = JokeRecommender(n_users, n_jokes, len(vector_concat))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.01), \n",
    "    loss='mean_squared_error', \n",
    "#     learning_rate=0.01,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(\n",
    "    log_dir=os.path.join(\"../logs\", str(time.time())),\n",
    "    histogram_freq=1)\n",
    "\n",
    "model.fit(\n",
    "    x=np.array(vector_concat),\n",
    "    y=np.array(ratings),\n",
    "    batch_size=100,\n",
    "    epochs=20,\n",
    "    callbacks=[tensorboard_callback],\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(np.array(vector_concat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.000000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.995058e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.264762e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.995054e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.995055e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.995055e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.995055e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.995055e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  2.000000e+04\n",
       "mean   9.995058e-01\n",
       "std    3.264762e-09\n",
       "min    9.995054e-01\n",
       "25%    9.995055e-01\n",
       "50%    9.995055e-01\n",
       "75%    9.995055e-01\n",
       "max    9.995055e-01"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99950552,  0.219     ],\n",
       "       [ 0.99950552, -9.281     ],\n",
       "       [ 0.99950552, -9.281     ],\n",
       "       [ 0.99950552, -6.781     ],\n",
       "       [ 0.99950552,  0.875     ],\n",
       "       [ 0.99950552, -9.656     ],\n",
       "       [ 0.99950552, -9.031     ],\n",
       "       [ 0.99950552, -7.469     ],\n",
       "       [ 0.99950552, -8.719     ],\n",
       "       [ 0.99950552, -9.156     ],\n",
       "       [ 0.99950552, -7.188     ],\n",
       "       [ 0.99950552, -8.781     ],\n",
       "       [ 0.99950552, -8.531     ],\n",
       "       [ 0.99950552, -7.906     ],\n",
       "       [ 0.99950552, -7.469     ],\n",
       "       [ 0.99950552,  9.812     ],\n",
       "       [ 0.99950552,  9.906     ],\n",
       "       [ 0.99950552,  0.75      ],\n",
       "       [ 0.99950552, -5.        ],\n",
       "       [ 0.99950552,  2.938     ],\n",
       "       [ 0.99950552,  2.        ],\n",
       "       [ 0.99950552, -0.156     ],\n",
       "       [ 0.99950552,  2.031     ],\n",
       "       [ 0.99950552,  5.688     ],\n",
       "       [ 0.99950552,  9.656     ],\n",
       "       [ 0.99950552,  8.        ],\n",
       "       [ 0.99950552,  9.312     ],\n",
       "       [ 0.99950552,  9.312     ],\n",
       "       [ 0.99950552,  8.781     ],\n",
       "       [ 0.99950552,  8.781     ],\n",
       "       [ 0.99950552,  8.781     ],\n",
       "       [ 0.99950552,  8.781     ],\n",
       "       [ 0.99950552,  8.781     ],\n",
       "       [ 0.99950552,  8.781     ],\n",
       "       [ 0.99950552,  8.781     ],\n",
       "       [ 0.99950552,  8.781     ],\n",
       "       [ 0.99950552,  8.781     ],\n",
       "       [ 0.99950552,  8.781     ],\n",
       "       [ 0.99950552,  8.781     ],\n",
       "       [ 0.99950552,  8.781     ],\n",
       "       [ 0.99950552,  8.781     ],\n",
       "       [ 0.99950552,  8.781     ],\n",
       "       [ 0.99950552,  8.781     ],\n",
       "       [ 0.99950552,  8.688     ],\n",
       "       [ 0.99950552,  8.688     ],\n",
       "       [ 0.99950552,  8.688     ],\n",
       "       [ 0.99950552,  8.688     ],\n",
       "       [ 0.99950552,  0.        ],\n",
       "       [ 0.99950552,  0.062     ],\n",
       "       [ 0.99950552,  0.062     ],\n",
       "       [ 0.99950552,  0.062     ],\n",
       "       [ 0.99950552,  0.219     ],\n",
       "       [ 0.99950552, -0.25      ],\n",
       "       [ 0.99950552,  0.062     ],\n",
       "       [ 0.99950552,  0.062     ],\n",
       "       [ 0.99950552, -0.125     ],\n",
       "       [ 0.99950552,  0.125     ],\n",
       "       [ 0.99950552,  0.031     ],\n",
       "       [ 0.99950552,  0.031     ],\n",
       "       [ 0.99950552,  3.625     ],\n",
       "       [ 0.99950552,  0.        ],\n",
       "       [ 0.99950552,  3.344     ],\n",
       "       [ 0.99950552, -9.688     ],\n",
       "       [ 0.99950552,  9.938     ],\n",
       "       [ 0.99950552,  9.531     ],\n",
       "       [ 0.99950552,  9.938     ],\n",
       "       [ 0.99950552,  0.406     ],\n",
       "       [ 0.99950552,  3.719     ],\n",
       "       [ 0.99950552,  9.656     ],\n",
       "       [ 0.99950552, -2.688     ],\n",
       "       [ 0.99950552, -9.562     ],\n",
       "       [ 0.99950552, -9.125     ],\n",
       "       [ 0.99950552,  9.938     ],\n",
       "       [ 0.99950552,  9.781     ],\n",
       "       [ 0.99950552,  9.812     ],\n",
       "       [ 0.99950552,  9.906     ],\n",
       "       [ 0.99950552,  3.125     ],\n",
       "       [ 0.99950552,  9.938     ],\n",
       "       [ 0.99950552,  9.844     ],\n",
       "       [ 0.99950552, -4.25      ],\n",
       "       [ 0.99950552,  5.125     ],\n",
       "       [ 0.99950552,  8.        ],\n",
       "       [ 0.99950552, -5.        ],\n",
       "       [ 0.99950552,  9.562     ],\n",
       "       [ 0.99950552,  9.844     ],\n",
       "       [ 0.99950552, -4.312     ],\n",
       "       [ 0.99950552,  4.781     ],\n",
       "       [ 0.99950552,  5.5       ],\n",
       "       [ 0.99950552,  4.969     ],\n",
       "       [ 0.99950552, -2.125     ],\n",
       "       [ 0.99950552,  4.75      ],\n",
       "       [ 0.99950552,  3.688     ],\n",
       "       [ 0.99950552, -0.312     ],\n",
       "       [ 0.99950552, -0.781     ],\n",
       "       [ 0.99950552,  3.938     ],\n",
       "       [ 0.99950552,  9.281     ],\n",
       "       [ 0.99950552, -9.844     ],\n",
       "       [ 0.99950552, -9.844     ],\n",
       "       [ 0.99950552, -7.219     ],\n",
       "       [ 0.99950552, -2.031     ],\n",
       "       [ 0.99950552, -9.938     ],\n",
       "       [ 0.99950552, -9.969     ],\n",
       "       [ 0.99950552, -9.875     ],\n",
       "       [ 0.99950552, -9.812     ],\n",
       "       [ 0.99950552, -9.781     ],\n",
       "       [ 0.99950552, -6.844     ],\n",
       "       [ 0.99950552, -9.812     ],\n",
       "       [ 0.99950552, -9.781     ],\n",
       "       [ 0.99950552, -9.812     ],\n",
       "       [ 0.99950552,  0.062     ],\n",
       "       [ 0.99950552,  0.        ],\n",
       "       [ 0.99950552,  1.25      ],\n",
       "       [ 0.99950552,  0.344     ],\n",
       "       [ 0.99950552, -9.812     ],\n",
       "       [ 0.99950552, -5.812     ],\n",
       "       [ 0.99950552, -4.5       ],\n",
       "       [ 0.99950552, -4.906     ],\n",
       "       [ 0.9995054 ,  6.906     ],\n",
       "       [ 0.99950552,  4.75      ],\n",
       "       [ 0.99950552, -5.906     ],\n",
       "       [ 0.99950552, -0.406     ],\n",
       "       [ 0.99950552, -4.031     ],\n",
       "       [ 0.99950552,  3.875     ],\n",
       "       [ 0.99950552,  6.219     ],\n",
       "       [ 0.99950552,  5.656     ],\n",
       "       [ 0.99950552,  6.094     ],\n",
       "       [ 0.99950552,  5.406     ],\n",
       "       [ 0.99950552,  0.25      ],\n",
       "       [ 0.99950552,  4.438     ],\n",
       "       [ 0.99950552,  5.562     ],\n",
       "       [ 0.99950552,  6.094     ],\n",
       "       [ 0.99950552,  0.5       ],\n",
       "       [ 0.99950552,  0.312     ],\n",
       "       [ 0.99950552,  3.812     ],\n",
       "       [ 0.99950552,  0.625     ],\n",
       "       [ 0.99950552,  1.969     ],\n",
       "       [ 0.99950552,  4.906     ],\n",
       "       [ 0.99950552,  4.469     ],\n",
       "       [ 0.99950552,  3.812     ],\n",
       "       [ 0.99950552,  0.469     ],\n",
       "       [ 0.99950552,  4.281     ],\n",
       "       [ 0.99950552,  0.438     ],\n",
       "       [ 0.99950552,  2.594     ],\n",
       "       [ 0.99950552,  0.781     ],\n",
       "       [ 0.99950552,  6.        ],\n",
       "       [ 0.99950552,  7.062     ],\n",
       "       [ 0.99950552,  6.375     ],\n",
       "       [ 0.99950552,  1.188     ],\n",
       "       [ 0.99950552,  0.562     ],\n",
       "       [ 0.99950552,  0.344     ],\n",
       "       [ 0.99950552,  8.        ],\n",
       "       [ 0.99950552,  2.281     ],\n",
       "       [ 0.99950552,  2.812     ],\n",
       "       [ 0.99950552,  1.188     ],\n",
       "       [ 0.99950552,  2.75      ],\n",
       "       [ 0.99950552,  4.375     ],\n",
       "       [ 0.99950552,  4.812     ],\n",
       "       [ 0.99950552,  1.438     ],\n",
       "       [ 0.99950552,  1.688     ],\n",
       "       [ 0.99950552,  3.906     ],\n",
       "       [ 0.99950552,  3.562     ],\n",
       "       [ 0.99950552,  2.875     ],\n",
       "       [ 0.99950552,  3.188     ],\n",
       "       [ 0.99950552,  3.219     ],\n",
       "       [ 0.99950552,  7.719     ],\n",
       "       [ 0.99950552,  6.281     ],\n",
       "       [ 0.99950552,  4.906     ],\n",
       "       [ 0.99950552,  5.75      ],\n",
       "       [ 0.99950552,  7.031     ],\n",
       "       [ 0.99950552,  6.25      ],\n",
       "       [ 0.99950552,  2.5       ],\n",
       "       [ 0.99950552,  3.906     ],\n",
       "       [ 0.99950552,  6.156     ],\n",
       "       [ 0.99950552,  5.781     ],\n",
       "       [ 0.99950552,  4.156     ],\n",
       "       [ 0.99950552,  4.812     ],\n",
       "       [ 0.99950552,  3.969     ],\n",
       "       [ 0.99950552,  4.188     ],\n",
       "       [ 0.99950552,  3.562     ],\n",
       "       [ 0.99950552,  0.531     ],\n",
       "       [ 0.99950552, -6.438     ],\n",
       "       [ 0.99950552, -0.031     ],\n",
       "       [ 0.99950552,  0.875     ],\n",
       "       [ 0.99950552,  0.906     ],\n",
       "       [ 0.99950552,  0.094     ],\n",
       "       [ 0.99950552,  0.406     ],\n",
       "       [ 0.99950552, -0.25      ],\n",
       "       [ 0.99950552,  0.156     ],\n",
       "       [ 0.99950552,  0.469     ],\n",
       "       [ 0.99950552, -7.906     ],\n",
       "       [ 0.99950552,  0.594     ],\n",
       "       [ 0.99950552,  0.469     ],\n",
       "       [ 0.99950552,  0.781     ],\n",
       "       [ 0.99950552,  0.344     ],\n",
       "       [ 0.99950552,  0.281     ],\n",
       "       [ 0.99950552,  0.844     ],\n",
       "       [ 0.99950552, -0.25      ],\n",
       "       [ 0.99950552,  1.062     ],\n",
       "       [ 0.99950552,  1.812     ],\n",
       "       [ 0.99950552, -0.031     ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.column_stack((result, ratings))[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
